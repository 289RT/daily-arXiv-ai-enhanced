{"id": "2506.16084", "pdf": "https://arxiv.org/pdf/2506.16084", "abs": "https://arxiv.org/abs/2506.16084", "authors": ["Zhichao Yan", "Yue Kang", "Buyong Ma"], "title": "Aptamer-protein interaction prediction model based on transformer", "categories": ["q-bio.BM"], "comment": null, "summary": "Aptamers are single-stranded DNA/RNAs or short peptides with unique tertiary\nstructures that selectively bind to specific targets. They have great potential\nin the detection and medical fields. Here, we present SelfTrans-Ensemble, a\ndeep learning model that integrates sequence information models and structural\ninformation models to extract multi-scale features for predicting\naptamer-protein interactions (APIs). The model employs two pre-trained models,\nProtBert and RNA-FM, to encode protein and aptamer sequences, along with\nfeatures generated from primary sequence and secondary structural information.\nTo address the data imbalance in the aptamer dataset imbalance, we incorporated\nshort RNA-protein interaction data in the training set. This resulted in a\ntraining accuracy of 98.9% and a test accuracy of 88.0%, demonstrating the\nmodel's effectiveness in accurately predicting APIs. Additionally, analysis\nusing molecular simulation indicated that SelfTrans-Ensemble is sensitive to\naptamer sequence mutations. We anticipate that SelfTrans-Ensemble can offer a\nmore efficient and rapid process for aptamer screening."}
{"id": "2506.17064", "pdf": "https://arxiv.org/pdf/2506.17064", "abs": "https://arxiv.org/abs/2506.17064", "authors": ["Aditya Sengar", "Ali Hariri", "Daniel Probst", "Patrick Barth", "Pierre Vandergheynst"], "title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "categories": ["q-bio.BM", "cs.LG"], "comment": "10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.\n  Code and data are publicly available", "summary": "Generating diverse, all-atom conformational ensembles of dynamic proteins\nsuch as G-protein-coupled receptors (GPCRs) is critical for understanding their\nfunction, yet most generative models simplify atomic detail or ignore\nconformational diversity altogether. We present latent diffusion for full\nprotein generation (LD-FPG), a framework that constructs complete all-atom\nprotein structures, including every side-chain heavy atom, directly from\nmolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural\nnetwork (ChebNet) to obtain low-dimensional latent embeddings of protein\nconformations, which are processed using three pooling strategies: blind,\nsequential and residue-based. A diffusion model trained on these latent\nrepresentations generates new samples that a decoder, optionally regularized by\ndihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a\n2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor\nin a membrane environment, the sequential and residue-based pooling strategy\nreproduces the reference ensemble with high structural fidelity (all-atom lDDT\nof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone\nand side-chain dihedral-angle distributions with a Jensen-Shannon divergence of\nless than 0.03 compared to the MD data. LD-FPG thereby offers a practical route\nto system-specific, all-atom ensemble generation for large proteins, providing\na promising tool for structure-based therapeutic design on complex, dynamic\ntargets. The D2R-MD dataset and our implementation are freely available to\nfacilitate further research."}
