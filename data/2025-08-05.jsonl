{"id": "2508.01799", "pdf": "https://arxiv.org/pdf/2508.01799", "abs": "https://arxiv.org/abs/2508.01799", "authors": ["Jing Lan", "Hexiao Ding", "Hongzhao Chen", "Yufeng Jiang", "Ng Nga Chun", "Gerald W. Y. Cheng", "Zongxi Li", "Jing Cai", "Liang-ting Lin", "Jung Sun Yoo"], "title": "Contrastive Multi-Task Learning with Solvent-Aware Augmentation for Drug Discovery", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "10 pages, 4 figures", "summary": "Accurate prediction of protein-ligand interactions is essential for\ncomputer-aided drug discovery. However, existing methods often fail to capture\nsolvent-dependent conformational changes and lack the ability to jointly learn\nmultiple related tasks. To address these limitations, we introduce a\npre-training method that incorporates ligand conformational ensembles generated\nunder diverse solvent conditions as augmented input. This design enables the\nmodel to learn both structural flexibility and environmental context in a\nunified manner. The training process integrates molecular reconstruction to\ncapture local geometry, interatomic distance prediction to model spatial\nrelationships, and contrastive learning to build solvent-invariant molecular\nrepresentations. Together, these components lead to significant improvements,\nincluding a 3.7% gain in binding affinity prediction, an 82% success rate on\nthe PoseBusters Astex docking benchmarks, and an area under the curve of 97.1%\nin virtual screening. The framework supports solvent-aware, multi-task modeling\nand produces consistent results across benchmarks. A case study further\ndemonstrates sub-angstrom docking accuracy with a root-mean-square deviation of\n0.157 angstroms, offering atomic-level insight into binding mechanisms and\nadvancing structure-based drug design."}
{"id": "2508.01924", "pdf": "https://arxiv.org/pdf/2508.01924", "abs": "https://arxiv.org/abs/2508.01924", "authors": ["Sharmi Banerjee", "Mostafa Karimi", "Melih Yilmaz", "Tommi Jaakkola", "Bella Dubrov", "Shang Shang", "Ron Benson"], "title": "Pi-SAGE: Permutation-invariant surface-aware graph encoder for binding affinity prediction", "categories": ["q-bio.BM"], "comment": null, "summary": "Protein surface fingerprint encodes chemical and geometric features that\ngovern protein-protein interactions and can be used to predict changes in\nbinding affinity between two protein complexes. Current state-of-the-art models\nfor predicting binding affinity change, such as GearBind, are all-atom based\ngeometric models derived from protein structures. Although surface properties\ncan be implicitly learned from the protein structure, we hypothesize that\nexplicit knowledge of protein surfaces can improve a structure-based model's\nability to predict changes in binding affinity. To this end, we introduce\nPi-SAGE, a novel Permutation-Invariant Surface-Aware Graph Encoder. We first\ntrain Pi-SAGE to create a protein surface codebook directly from the structure\nand assign a token for each surface-exposed residue. Next, we augment the node\nfeatures of the GearBind model with surface features from domain-adapted\nPi-SAGE to predict binding affinity change on the SKEMPI dataset. We show that\nexplicitly incorporating local, context-aware chemical properties of residues\nenhances the predictive power of all-atom graph neural networks in modeling\nbinding affinity changes between wild-type and mutant proteins."}
{"id": "2508.01055", "pdf": "https://arxiv.org/pdf/2508.01055", "abs": "https://arxiv.org/abs/2508.01055", "authors": ["Xuan Liu", "Siru Ouyang", "Xianrui Zhong", "Jiawei Han", "Huimin Zhao"], "title": "FGBench: A Dataset and Benchmark for Molecular Property Reasoning at Functional Group-Level in Large Language Models", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "comment": "20 pages, 20 figures", "summary": "Large language models (LLMs) have gained significant attention in chemistry.\nHowever, most existing datasets center on molecular-level property prediction\nand overlook the role of fine-grained functional group (FG) information.\nIncorporating FG-level data can provide valuable prior knowledge that links\nmolecular structures with textual descriptions, which can be used to build more\ninterpretable, structure-aware LLMs for reasoning on molecule-related tasks.\nMoreover, LLMs can learn from such fine-grained information to uncover hidden\nrelationships between specific functional groups and molecular properties,\nthereby advancing molecular design and drug discovery. Here, we introduce\nFGBench, a dataset comprising 625K molecular property reasoning problems with\nfunctional group information. Functional groups are precisely annotated and\nlocalized within the molecule, which ensures the dataset's interoperability\nthereby facilitating further multimodal applications. FGBench includes both\nregression and classification tasks on 245 different functional groups across\nthree categories for molecular property reasoning: (1) single functional group\nimpacts, (2) multiple functional group interactions, and (3) direct molecular\ncomparisons. In the benchmark of state-of-the-art LLMs on 7K curated data, the\nresults indicate that current LLMs struggle with FG-level property reasoning,\nhighlighting the need to enhance reasoning capabilities in LLMs for chemistry\ntasks. We anticipate that the methodology employed in FGBench to construct\ndatasets with functional group-level information will serve as a foundational\nframework for generating new question-answer pairs, enabling LLMs to better\nunderstand fine-grained molecular structure-property relationships. The dataset\nand evaluation code are available at\n\\href{https://github.com/xuanliugit/FGBench}{https://github.com/xuanliugit/FGBench}."}
