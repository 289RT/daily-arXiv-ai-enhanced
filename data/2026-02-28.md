<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [CryoNet.Refine: A One-step Diffusion Model for Rapid Refinement of Structural Models with Cryo-EM Density Map Restraints](https://arxiv.org/abs/2602.22263)
*Fuyao Huang,Xiaozhu Yu,Kui Xu,Qiangfeng Cliff Zhang*

Main category: q-bio.BM

TL;DR: CryoNet.Refine是一个端到端的深度学习框架，用于自动化加速冷冻电镜结构优化，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统冷冻电镜结构优化方法计算成本高且依赖人工调参，亟需高效自动化解决方案。

Method: 基于扩散模型结合密度感知损失函数和立体化学约束，一步优化结构。

Result: CryoNet.Refine在模型与密度图的关联性及几何质量上远超传统方法。

Conclusion: CryoNet.Refine为冷冻电镜结构优化提供了可扩展、自动化且强大的工具。

Abstract: High-resolution structure determination by cryo-electron microscopy (cryo-EM) requires the accurate fitting of an atomic model into an experimental density map. Traditional refinement pipelines such as Phenix.real_space_refine and Rosetta are computationally expensive, demand extensive manual tuning, and present a significant bottleneck for researchers. We present CryoNet.Refine, an end-to-end deep learning framework that automates and accelerates molecular structure refinement. Our approach utilizes a one-step diffusion model that integrates a density-aware loss function with robust stereochemical restraints, enabling rapid optimization of a structure against experimental data. CryoNet.Refine provides a unified and versatile solution capable of refining protein complexes as well as DNA/RNA-protein complexes. In benchmarks against Phenix.real_space_refine, CryoNet.Refine consistently achieves substantial improvements in both model-map correlation and overall geometric quality metrics. By offering a scalable, automated, and powerful alternative, CryoNet.Refine aims to serve as an essential tool for next-generation cryo-EM structure refinement. Web server: https://cryonet.ai/refine; Source code: https://github.com/kuixu/cryonet.refine.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Induction Meets Biology: Mechanisms of Repeat Detection in Protein Language Models](https://arxiv.org/abs/2602.23179)
*Gal Kesten-Pomeranz,Yaniv Nikankin,Anja Reusch,Tomer Tsaban,Ora Schueler-Furman,Yonatan Belinkov*

Main category: cs.LG

TL;DR: 该论文研究了蛋白质语言模型（PLMs）如何通过内部机制检测蛋白质序列中的精确和近似重复片段，揭示了两种阶段的机制，并结合了语言模式匹配和生物知识。


<details>
  <summary>Details</summary>
Motivation: 蛋白质序列中存在大量重复片段（精确和近似），这些片段对蛋白质结构和功能至关重要，因此需要研究PLMs如何检测这些重复。

Method: 通过分析PLMs在掩码标记预测中的行为，研究了其对精确和近似重复片段的检测机制，揭示了两阶段过程：特征表示构建和对齐标记的注意力机制。

Result: PLMs通过通用位置注意力头和生物专业化组件（如编码氨基酸相似性的神经元）构建特征表示，然后通过归纳头促进正确答案的生成。

Conclusion: PLMs结合了语言模式匹配和生物知识来解决这一生物任务，为研究更复杂的进化过程奠定了基础。

Abstract: Protein sequences are abundant in repeating segments, both as exact copies and as approximate segments with mutations. These repeats are important for protein structure and function, motivating decades of algorithmic work on repeat identification. Recent work has shown that protein language models (PLMs) identify repeats, by examining their behavior in masked-token prediction. To elucidate their internal mechanisms, we investigate how PLMs detect both exact and approximate repeats. We find that the mechanism for approximate repeats functionally subsumes that of exact repeats. We then characterize this mechanism, revealing two main stages: PLMs first build feature representations using both general positional attention heads and biologically specialized components, such as neurons that encode amino-acid similarity. Then, induction heads attend to aligned tokens across repeated segments, promoting the correct answer. Our results reveal how PLMs solve this biological task by combining language-based pattern matching with specialized biological knowledge, thereby establishing a basis for studying more complex evolutionary processes in PLMs.

</details>
