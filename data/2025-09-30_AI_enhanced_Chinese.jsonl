{"id": "2509.23254", "pdf": "https://arxiv.org/pdf/2509.23254", "abs": "https://arxiv.org/abs/2509.23254", "authors": ["Zhang-Yu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "title": "ABConformer: Physics-inspired Sliding Attention for Antibody-Antigen Interface Prediction", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Accurate prediction of antibody-antigen (Ab-Ag) interfaces is critical for\nvaccine design, immunodiagnostics, and therapeutic antibody development.\nHowever, achieving reliable predictions from sequences alone remains a\nchallenge. In this paper, we present ABCONFORMER, a model based on the\nConformer backbone that captures both local and global features of a\nbiosequence. To accurately capture Ab-Ag interactions, we introduced the\nphysics-inspired sliding attention, enabling residue-level contact recovery\nwithout relying on three-dimensional structural data. ABConformer can\naccurately predict paratopes and epitopes given the antibody and antigen\nsequence, and predict pan-epitopes on the antigen without antibody information.\nIn comparison experiments, ABCONFORMER achieves state-of-the-art performance on\na recent SARS-CoV-2 Ab-Ag dataset, and surpasses widely used sequence-based\nmethods for antibody-agnostic epitope prediction. Ablation studies further\nquantify the contribution of each component, demonstrating that, compared to\nconventional cross-attention, sliding attention significantly enhances the\nprecision of epitope prediction. To facilitate reproducibility, we will release\nthe code under an open-source license upon acceptance.", "AI": {"tldr": "ABCONFORMER\u662f\u4e00\u79cd\u57fa\u4e8eConformer\u4e3b\u5e72\u7684\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u4e09\u7ef4\u7ed3\u6784\u6570\u636e\u5373\u53ef\u51c6\u786e\u9884\u6d4b\u6297\u4f53-\u6297\u539f\u754c\u9762\u3002\u5b83\u5728\u6700\u65b0\u7684SARS-CoV-2\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u8d85\u8d8a\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u4e8e\u5e8f\u5217\u7684\u65b9\u6cd5\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u6297\u4f53-\u6297\u539f\u754c\u9762\u5bf9\u4e8e\u75ab\u82d7\u8bbe\u8ba1\u3001\u514d\u75ab\u8bca\u65ad\u548c\u6cbb\u7597\u6297\u4f53\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4ec5\u4ece\u5e8f\u5217\u8fdb\u884c\u53ef\u9760\u9884\u6d4b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "ABCONFORMER\u5f15\u5165\u4e86\u7269\u7406\u542f\u53d1\u7684\u6ed1\u52a8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u4e09\u7ef4\u7ed3\u6784\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u6355\u83b7\u6297\u4f53-\u6297\u539f\u76f8\u4e92\u4f5c\u7528\u7684\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u3002", "result": "ABCONFORMER\u5728SARS-CoV-2\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff0c\u5e76\u5728\u6297\u4f53\u65e0\u5173\u7684\u8868\u4f4d\u9884\u6d4b\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6ed1\u52a8\u6ce8\u610f\u529b\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "ABCONFORMER\u4e3a\u5e8f\u5217\u7ea7\u522b\u7684\u6297\u4f53-\u6297\u539f\u754c\u9762\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u53ef\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2509.24779", "pdf": "https://arxiv.org/pdf/2509.24779", "abs": "https://arxiv.org/abs/2509.24779", "authors": ["Kacper Kapu\u015bniak", "Cristian Gabellini", "Michael Bronstein", "Prudencio Tossou", "Francesco Di Giovanni"], "title": "MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Molecular Dynamics (MD) is a powerful computational microscope for probing\nprotein functions. However, the need for fine-grained integration and the long\ntimescales of biomolecular events make MD computationally expensive. To address\nthis, several generative models have been proposed to generate surrogate\ntrajectories at lower cost. Yet, these models typically learn a fixed-lag\ntransition density, causing the training signal to be dominated by frequent but\nuninformative transitions. We introduce a new class of generative models, MSM\nEmulators, which instead learn to sample transitions across discrete states\ndefined by an underlying Markov State Model (MSM). We instantiate this class\nwith Markov Space Flow Matching (MarS-FM), whose sampling offers more than two\norders of magnitude speedup compared to implicit- or explicit-solvent MD\nsimulations. We benchmark Mars-FM ability to reproduce MD statistics through\nstructural observables such as RMSD, radius of gyration, and secondary\nstructure content. Our evaluation spans protein domains (up to 500 residues)\nwith significant chemical and structural diversity, including unfolding events,\nand enforces strict sequence dissimilarity between training and test sets to\nassess generalization. Across all metrics, MarS-FM outperforms existing\nmethods, often by a substantial margin.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6a21\u578bMSM Emulators\uff0c\u901a\u8fc7\u5b66\u4e60\u9a6c\u5c14\u53ef\u592b\u72b6\u6001\u6a21\u578b\uff08MSM\uff09\u5b9a\u4e49\u7684\u79bb\u6563\u72b6\u6001\u7684\u8dc3\u8fc1\uff0c\u663e\u8457\u63d0\u9ad8\u86cb\u767d\u8d28\u52a8\u529b\u5b66\u6a21\u62df\u7684\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5206\u5b50\u52a8\u529b\u5b66\uff08MD\uff09\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u751f\u6210\u6a21\u578b\u66ff\u4ee3\u6602\u8d35\u7684MD\u6a21\u62df\u3002", "method": "\u5f15\u5165\u4e86MarS-FM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60MSM\u7684\u79bb\u6563\u72b6\u6001\u8dc3\u8fc1\uff0c\u751f\u6210\u9ad8\u6548\u7684\u66ff\u4ee3\u8f68\u8ff9\u3002", "result": "MarS-FM\u5728\u591a\u7c7b\u86cb\u767d\u8d28\u7ed3\u6784\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u8d85\u8fc7\u4e24\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "conclusion": "MSM Emulators\u548cMarS-FM\u5728\u86cb\u767d\u8d28\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.25171", "pdf": "https://arxiv.org/pdf/2509.25171", "abs": "https://arxiv.org/abs/2509.25171", "authors": ["Sophia Tang", "Yuchen Zhu", "Molei Tao", "Pranam Chatterjee"], "title": "TR2-D2: Tree Search Guided Trajectory-Aware Fine-Tuning for Discrete Diffusion", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Reinforcement learning with stochastic optimal control offers a promising\nframework for diffusion fine-tuning, where a pre-trained diffusion model is\noptimized to generate paths that lead to a reward-tilted distribution. While\nthese approaches enable optimization without access to explicit samples from\nthe optimal distribution, they require training on rollouts under the current\nfine-tuned model, making them susceptible to reinforcing sub-optimal\ntrajectories that yield poor rewards. To overcome this challenge, we introduce\nTRee Search Guided TRajectory-Aware Fine-Tuning for Discrete Diffusion\n(TR2-D2), a novel framework that optimizes reward-guided discrete diffusion\ntrajectories with tree search to construct replay buffers for trajectory-aware\nfine-tuning. These buffers are generated using Monte Carlo Tree Search (MCTS)\nand subsequently used to fine-tune a pre-trained discrete diffusion model under\na stochastic optimal control objective. We validate our framework on single-\nand multi-objective fine-tuning of biological sequence diffusion models,\nhighlighting the overall effectiveness of TR2-D2 for reliable reward-guided\nfine-tuning in discrete sequence generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aTR2-D2\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6811\u641c\u7d22\u548c\u968f\u673a\u6700\u4f18\u63a7\u5236\uff0c\u4f18\u5316\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u8f68\u8ff9\uff0c\u4ee5\u5b9e\u73b0\u5956\u52b1\u5f15\u5bfc\u7684\u7cbe\u7ec6\u8c03\u4f18\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6269\u6563\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\u5bb9\u6613\u56e0\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6b21\u4f18\u8f68\u8ff9\u800c\u4ea7\u751f\u4e0d\u826f\u7ed3\u679c\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u7cbe\u7ec6\u8c03\u4f18\u3002", "method": "TR2-D2\u6846\u67b6\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u6784\u5efa\u56de\u653e\u7f13\u51b2\u533a\uff0c\u7528\u4e8e\u8f68\u8ff9\u611f\u77e5\u7684\u7cbe\u7ec6\u8c03\u4f18\uff0c\u5e76\u7ed3\u5408\u968f\u673a\u6700\u4f18\u63a7\u5236\u76ee\u6807\u4f18\u5316\u9884\u8bad\u7ec3\u7684\u79bb\u6563\u6269\u6563\u6a21\u578b\u3002", "result": "\u5728\u751f\u7269\u5e8f\u5217\u6269\u6563\u6a21\u578b\u7684\u5355\u76ee\u6807\u548c\u591a\u76ee\u6807\u7cbe\u7ec6\u8c03\u4f18\u4efb\u52a1\u4e2d\uff0cTR2-D2\u5c55\u73b0\u51fa\u4e86\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "TR2-D2\u4e3a\u79bb\u6563\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u5956\u52b1\u5f15\u5bfc\u7cbe\u7ec6\u8c03\u4f18\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
