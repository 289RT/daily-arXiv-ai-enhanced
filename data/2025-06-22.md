<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [PFMBench: Protein Foundation Model Benchmark](https://arxiv.org/abs/2506.14796)
*Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li*

Main category: q-bio.BM

TL;DR: 研究调查了蛋白质基础模型研究的现状和未来方向，提出了PFMBench作为全面评估蛋白质基础模型的基准。


<details>
  <summary>Details</summary>
Motivation: 当前蛋白质基础模型研究缺乏全面的评估基准，限制了对其泛化能力和局限性的深入理解。

Method: 提出PFMBench，一个涵盖38个任务和8个关键领域的评估基准，对17个最新模型进行了数百项实验。

Result: PFMBench揭示了任务间的相关性，识别了表现最佳的模型，并提供了简化的评估协议。

Conclusion: PFMBench填补了蛋白质基础模型评估的空白，为未来的研究提供了重要参考。

Abstract: This study investigates the current landscape and future directions of
protein foundation model research. While recent advancements have transformed
protein science and engineering, the field lacks a comprehensive benchmark for
fair evaluation and in-depth understanding. Since ESM-1B, numerous protein
foundation models have emerged, each with unique datasets and methodologies.
However, evaluations often focus on limited tasks tailored to specific models,
hindering insights into broader generalization and limitations. Specifically,
researchers struggle to understand the relationships between tasks, assess how
well current models perform across them, and determine the criteria in
developing new foundation models. To fill this gap, we present PFMBench, a
comprehensive benchmark evaluating protein foundation models across 38 tasks
spanning 8 key areas of protein science. Through hundreds of experiments on 17
state-of-the-art models across 38 tasks, PFMBench reveals the inherent
correlations between tasks, identifies top-performing models, and provides a
streamlined evaluation protocol. Code is available at
\href{https://github.com/biomap-research/PFMBench}{\textcolor{blue}{GitHub}}.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation](https://arxiv.org/abs/2506.15309)
*Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar*

Main category: cs.LG

TL;DR: 提出了一种结合序列到序列变分自编码器的结构化主动学习方法，用于优化多靶点药物设计，成功生成了针对三种冠状病毒蛋白酶的结构多样性候选分子。


<details>
  <summary>Details</summary>
Motivation: 多靶点药物设计因稀疏奖励和冲突的设计约束而具有挑战性，需要一种高效的方法来平衡化学多样性和多靶点亲和力。

Method: 结合序列到序列变分自编码器的主动学习框架，交替扩展化学可行的潜在空间和逐步约束分子以满足多靶点对接阈值。

Result: 在针对三种冠状病毒主蛋白酶的研究中，成功生成了结构多样的泛抑制剂候选分子。

Conclusion: 该框架为复杂多药效景观提供了一种通用的计算设计路线图，提升了高效探索有益化学空间的能力。

Abstract: Simultaneously optimizing molecules against multiple therapeutic targets
remains a profound challenge in drug discovery, particularly due to sparse
rewards and conflicting design constraints. We propose a structured active
learning (AL) paradigm integrating a sequence-to-sequence (Seq2Seq) variational
autoencoder (VAE) into iterative loops designed to balance chemical diversity,
molecular quality, and multi-target affinity. Our method alternates between
expanding chemically feasible regions of latent space and progressively
constraining molecules based on increasingly stringent multi-target docking
thresholds. In a proof-of-concept study targeting three related coronavirus
main proteases (SARS-CoV-2, SARS-CoV, MERS-CoV), our approach efficiently
generated a structurally diverse set of pan-inhibitor candidates. We
demonstrate that careful timing and strategic placement of chemical filters
within this active learning pipeline markedly enhance exploration of beneficial
chemical space, transforming the sparse-reward, multi-objective drug design
problem into an accessible computational task. Our framework thus provides a
generalizable roadmap for efficiently navigating complex polypharmacological
landscapes.

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [3] [Engineering Supercomputing Platforms for Biomolecular Applications](https://arxiv.org/abs/2506.15585)
*Robert Welch,Charles Laughton,Oliver Henrich,Tom Burnley,Daniel Cole,Alan Real,Sarah Harris,James Gebbie-Rayet*

Main category: physics.bio-ph

TL;DR: 论文对多种计算生物学软件在不同HPC硬件上的性能、能效和数据存储需求进行了基准测试，发现硬件多样性对支持不同计算生物任务至关重要。GPU通常最有效，但某些任务仍需CPU。数据存储和管理复杂性是主要挑战，建议通过招聘DevOps专家、扩展联盟模式和采用容器化工具来改善。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估计算生物学软件在多样化HPC硬件上的性能与效率，以帮助选择最适合不同任务的硬件类型，并解决数据存储和系统管理中的实际问题。

Method: 通过在AMD EPYC CPU、NVIDIA和AMD GPU节点等硬件上运行GROMACS、AMBER等软件，评估性能、能效、数据存储需求和用户体验等指标。

Result: 结果表明，硬件多样性对支持不同计算生物学任务至关重要；GPU对大多数任务最有效，但某些仍需CPU；数据存储需求和管理复杂度是主要挑战。

Conclusion: 建议采用多样化的HPC硬件选择，并通过DevOps培训、联盟模式扩展和容器化工具来优化系统管理和数据存储。

Abstract: A range of computational biology software (GROMACS, AMBER, NAMD, LAMMPS,
OpenMM, Psi4 and RELION) was benchmarked on a representative selection of HPC
hardware, including AMD EPYC 7742 CPU nodes, NVIDIA V100 and AMD MI250X GPU
nodes, and an NVIDIA GH200 testbed. The raw performance, power efficiency and
data storage requirements of the software was evaluated for each HPC facility,
along with qualitative factors such as the user experience and software
environment. It was found that the diversity of methods used within
computational biology means that there is no single HPC hardware that can
optimally run every type of HPC job, and that diverse hardware is the only way
to properly support all methods. New hardware, such as AMD GPUs and Nvidia AI
chips, are mostly compatible with existing methods, but are also more
labour-intensive to support. GPUs offer the most efficient way to run most
computational biology tasks, though some tasks still require CPUs. A fast HPC
node running molecular dynamics can produce around 10GB of data per day,
however, most facilities and research institutions lack short-term and
long-term means to store this data. Finally, as the HPC landscape has become
more complex, deploying software and keeping HPC systems online has become more
difficult. This situation could be improved through hiring/training in DevOps
practices, expanding the consortium model to provide greater support to HPC
system administrators, and implementing build
frameworks/containerisation/virtualisation tools to allow users to configure
their own software environment, rather than relying on centralised software
installations.

</details>
