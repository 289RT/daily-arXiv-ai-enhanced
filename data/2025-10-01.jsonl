{"id": "2509.25479", "pdf": "https://arxiv.org/pdf/2509.25479", "abs": "https://arxiv.org/abs/2509.25479", "authors": ["Zhenfeng Deng", "Ruijie Hou", "Ningrui Xie", "Mike Tyers", "Micha≈Ç Koziarski"], "title": "Discontinuous Epitope Fragments as Sufficient Target Templates for Efficient Binder Design", "categories": ["q-bio.BM", "cs.AI"], "comment": "Accepted by NeurIPS2025-AI4Science", "summary": "Recent advances in structure-based protein design have accelerated de novo\nbinder generation, yet interfaces on large domains or spanning multiple domains\nremain challenging due to high computational cost and declining success with\nincreasing target size. We hypothesized that protein folding neural networks\n(PFNNs) operate in a ``local-first'' manner, prioritizing local interactions\nwhile displaying limited sensitivity to global foldability.Guided by this\nhypothesis, we propose an epitope-only strategy that retains only the\ndiscontinuous surface residues surrounding the binding site. Compared to\nintact-domain workflows, this approach improves in silico success rates by up\nto 80% and reduces the average time per successful design by up to forty-fold,\nenabling binder design against previously intractable targets such as ClpP and\nALS3. Building on this foundation, we further developed a tailored pipeline\nthat incorporates a Monte Carlo-based evolution step to overcome local minima\nand a position-specific biased inverse folding step to refine sequence\npatterns. Together, these advances not only establish a generalizable framework\nfor efficient binder design against structurally large and otherwise\ninaccessible targets, but also support the broader ``local-first'' hypothesis\nas a guiding principle for PFNN-based design."}
{"id": "2509.25872", "pdf": "https://arxiv.org/pdf/2509.25872", "abs": "https://arxiv.org/abs/2509.25872", "authors": ["Yan Wang", "Hao Wu", "Simon Olsson"], "title": "Marginal Girsanov Reweighting: Stable Variance Reduction via Neural Ratio Estimation", "categories": ["q-bio.QM", "q-bio.BM"], "comment": null, "summary": "Recovering unbiased properties from biased or perturbed simulations is a\ncentral challenge in rare-event sampling. Classical Girsanov Reweighting (GR)\noffers a principled solution by yielding exact pathwise probability ratios\nbetween perturbed and reference processes. However, the variance of GR weights\ngrows rapidly with time, rendering it impractical for long-horizon reweighting.\nWe introduce Marginal Girsanov Reweighting (MGR), which mitigates variance\nexplosion by marginalizing over intermediate paths, producing stable and\nscalable weights for long-timescale dynamics. Experiments demonstrate that MGR\n(i) accurately recovers kinetic properties from umbrella-sampling trajectories\nin molecular dynamics, and (ii) enables efficient Bayesian parameter inference\nfor stochastic differential equations with temporally sparse observations."}
{"id": "2509.26566", "pdf": "https://arxiv.org/pdf/2509.26566", "abs": "https://arxiv.org/abs/2509.26566", "authors": ["JunJie Wee", "Faisal Suwayyid", "Mushal Zia", "Hongsong Feng", "Yuta Hozumi", "Guo-Wei Wei"], "title": "Commutative algebra neural network reveals genetic origins of diseases", "categories": ["q-bio.QM", "math.AC", "q-bio.BM"], "comment": null, "summary": "Genetic mutations can disrupt protein structure, stability, and solubility,\ncontributing to a wide range of diseases. Existing predictive models often lack\ninterpretability and fail to integrate physical and chemical interactions\ncritical to molecular mechanisms. Moreover, current approaches treat disease\nassociation, stability changes, and solubility alterations as separate tasks,\nlimiting model generalizability. In this study, we introduce a unified\nframework based on multiscale commutative algebra to capture intrinsic physical\nand chemical interactions for the first time. Leveraging Persistent\nStanley-Reisner Theory, we extract multiscale algebraic invariants to build a\nCommutative Algebra neural Network (CANet). Integrated with transformer\nfeatures and auxiliary physical features, we apply CANet to tackle three key\ndomains for the first time: disease-associated mutations, mutation-induced\nprotein stability changes, and solubility changes upon mutations. Across six\nbenchmark tasks, CANet and its gradient boosting tree counterpart, CATree,\nconsistently attain state-of-the-art performance, achieving up to 7.5%\nimprovement in predictive accuracy. Our approach offers multiscale,\nmechanistic, interpretable,and generalizable models for predicting\ndisease-mutation associations."}
