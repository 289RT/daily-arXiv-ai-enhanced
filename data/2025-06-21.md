<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [PFMBench: Protein Foundation Model Benchmark](https://arxiv.org/abs/2506.14796)
*Zhangyang Gao,Hao Wang,Cheng Tan,Chenrui Xu,Mengdi Liu,Bozhen Hu,Linlin Chao,Xiaoming Zhang,Stan Z. Li*

Main category: q-bio.BM

TL;DR: 这篇论文提出了PFMBench，一个用于全面评估蛋白质基础模型的基准测试，涵盖了38个任务和8个关键领域，填补了当前缺乏统一评估标准的空白。


<details>
  <summary>Details</summary>
Motivation: 蛋白质基础模型研究缺乏统一的评估基准，导致难以全面比较不同模型的性能和局限性。

Method: 作者开发了PFMBench，对17种前沿模型在38个任务上进行了数百次实验，并分析了任务间的相关性。

Result: PFMBench揭示了任务间的内在关联，并识别出表现最佳的模型，同时提供了简化的评估流程。

Conclusion: 该研究为蛋白质基础模型的评估和发展提供了重要工具，促进了领域的标准化和深入理解。

Abstract: This study investigates the current landscape and future directions of
protein foundation model research. While recent advancements have transformed
protein science and engineering, the field lacks a comprehensive benchmark for
fair evaluation and in-depth understanding. Since ESM-1B, numerous protein
foundation models have emerged, each with unique datasets and methodologies.
However, evaluations often focus on limited tasks tailored to specific models,
hindering insights into broader generalization and limitations. Specifically,
researchers struggle to understand the relationships between tasks, assess how
well current models perform across them, and determine the criteria in
developing new foundation models. To fill this gap, we present PFMBench, a
comprehensive benchmark evaluating protein foundation models across 38 tasks
spanning 8 key areas of protein science. Through hundreds of experiments on 17
state-of-the-art models across 38 tasks, PFMBench reveals the inherent
correlations between tasks, identifies top-performing models, and provides a
streamlined evaluation protocol. Code is available at
\href{https://github.com/biomap-research/PFMBench}{\textcolor{blue}{GitHub}}.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target Inhibitor Generation](https://arxiv.org/abs/2506.15309)
*Júlia Vilalta-Mor,Alexis Molina,Laura Ortega Varga,Isaac Filella-Merce,Victor Guallar*

Main category: cs.LG

TL;DR: 论文提出了一种结合序列到序列变分自编码器和主动学习的结构化方法，用于优化多靶点药物设计，解决了稀疏奖励和冲突设计约束的问题。


<details>
  <summary>Details</summary>
Motivation: 多靶点药物设计因稀疏奖励和冲突约束而极具挑战性，需要一种高效方法来平衡化学多样性和多靶点亲和力。

Method: 采用主动学习范式，结合Seq2Seq变分自编码器，交替扩展潜在空间化学多样性和逐步约束分子以满足多靶点对接阈值。

Result: 在针对冠状病毒主蛋白酶的实验中，成功生成了一组结构多样的泛抑制剂候选分子。

Conclusion: 该方法显著提升了化学空间探索效率，为复杂多靶点药物设计提供了通用框架。

Abstract: Simultaneously optimizing molecules against multiple therapeutic targets
remains a profound challenge in drug discovery, particularly due to sparse
rewards and conflicting design constraints. We propose a structured active
learning (AL) paradigm integrating a sequence-to-sequence (Seq2Seq) variational
autoencoder (VAE) into iterative loops designed to balance chemical diversity,
molecular quality, and multi-target affinity. Our method alternates between
expanding chemically feasible regions of latent space and progressively
constraining molecules based on increasingly stringent multi-target docking
thresholds. In a proof-of-concept study targeting three related coronavirus
main proteases (SARS-CoV-2, SARS-CoV, MERS-CoV), our approach efficiently
generated a structurally diverse set of pan-inhibitor candidates. We
demonstrate that careful timing and strategic placement of chemical filters
within this active learning pipeline markedly enhance exploration of beneficial
chemical space, transforming the sparse-reward, multi-objective drug design
problem into an accessible computational task. Our framework thus provides a
generalizable roadmap for efficiently navigating complex polypharmacological
landscapes.

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [3] [Engineering Supercomputing Platforms for Biomolecular Applications](https://arxiv.org/abs/2506.15585)
*Robert Welch,Charles Laughton,Oliver Henrich,Tom Burnley,Daniel Cole,Alan Real,Sarah Harris,James Gebbie-Rayet*

Main category: physics.bio-ph

TL;DR: 论文通过比较多种HPC硬件在计算生物学软件上的表现，指出多样性硬件是支持所有方法的唯一途径，同时提出改进HPC系统管理的建议。


<details>
  <summary>Details</summary>
Motivation: 评估不同HPC硬件在计算生物学软件中的性能、能效和数据存储需求，以指导硬件选择和系统优化。

Method: 对多种HPC硬件（如AMD EPYC CPU、NVIDIA和AMD GPU）进行基准测试，对比性能、能效和软件环境等因素。

Result: 发现GPU是运行大多数计算生物学任务的最有效方式，但CPU仍有需求；数据存储和管理成为新的挑战。

Conclusion: 需采用多样化的硬件解决方案，并通过培训、工具和合作模式改进HPC系统的部署和维护。

Abstract: A range of computational biology software (GROMACS, AMBER, NAMD, LAMMPS,
OpenMM, Psi4 and RELION) was benchmarked on a representative selection of HPC
hardware, including AMD EPYC 7742 CPU nodes, NVIDIA V100 and AMD MI250X GPU
nodes, and an NVIDIA GH200 testbed. The raw performance, power efficiency and
data storage requirements of the software was evaluated for each HPC facility,
along with qualitative factors such as the user experience and software
environment. It was found that the diversity of methods used within
computational biology means that there is no single HPC hardware that can
optimally run every type of HPC job, and that diverse hardware is the only way
to properly support all methods. New hardware, such as AMD GPUs and Nvidia AI
chips, are mostly compatible with existing methods, but are also more
labour-intensive to support. GPUs offer the most efficient way to run most
computational biology tasks, though some tasks still require CPUs. A fast HPC
node running molecular dynamics can produce around 10GB of data per day,
however, most facilities and research institutions lack short-term and
long-term means to store this data. Finally, as the HPC landscape has become
more complex, deploying software and keeping HPC systems online has become more
difficult. This situation could be improved through hiring/training in DevOps
practices, expanding the consortium model to provide greater support to HPC
system administrators, and implementing build
frameworks/containerisation/virtualisation tools to allow users to configure
their own software environment, rather than relying on centralised software
installations.

</details>
