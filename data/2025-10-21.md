<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [CryoDyna: Multiscale end-to-end modeling of cryo-EM macromolecule dynamics with physics-aware neural network](https://arxiv.org/abs/2510.16510)
*Chengwei Zhang,Shimian Li,Yihao Niu,Zhen Zhu,Sihao Yuan,Sirui Liu,Yi Qin Gao*

Main category: q-bio.BM

TL;DR: CryoDyna是一种基于深度学习的框架，通过整合跨视图注意力和多尺度变形建模，直接从2D投影中推断大分子动力学，填补了冷冻电镜异质性分析与原子尺度结构动力学之间的空白。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜单颗粒分析在解析构象异质性方面面临挑战，现有方法缺乏原子细节或易因图像噪声和单视图信息有限而过拟合。

Method: 结合粗粒度MARTINI表示和原子反向映射，CryoDyna实现蛋白质构象景观的近原子级解析。

Result: 在多个模拟和实验数据集上验证，CryoDyna展现出更高的建模准确性，并能稳健地恢复冷冻电镜颗粒堆中隐藏的多尺度复杂结构变化。

Conclusion: CryoDyna为探索复杂生物机制提供了有前景的工具。

Abstract: Single-particle cryo-EM has transformed structural biology but still faces
challenges in resolving conformational heterogeneity at atomic resolution.
Existing cryo-EM heterogeneity analysis methods either lack atomic details or
tend to subject to overfitting due to image noise and limited information in
single views. To obtain atomic detailed multiple conformations and make full
use of particle images of different orientations, we present here CryoDyna, a
deep learning framework to infer macromolecular dynamics directly from 2D
projections by integrating cross-view attention and multi-scale deformation
modeling. Combining coarse-grained MARTINI representation with atomic
backmapping, CryoDyna achieves near-atomic interpretation of protein
conformational landscapes. Validated on multiple simulated and experimental
datasets, CryoDyna demonstrates improved modeling accuracy and robustly
recovers multi-scale complex structure changes hidden in the cryo-EM particle
stacks. As examples, we generated protein-RNA coordinated motions, resolved
dynamics in the unseen region of RAG signal end complex, mapped translocating
ribosome states in a one-shot manner, and revealed step-wise closure of a
membrane-anchored protein multimer. This work bridges the gap between cryo-EM
heterogeneity analysis and atomic-scale structural dynamics, offering a
promising tool for exploration of complex biological mechanisms.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [2] [Accelerated Learning on Large Scale Screens using Generative Library Models](https://arxiv.org/abs/2510.16612)
*Eli N. Weinstein,Andrei Slabodkin,Mattia G. Gollub,Elizabeth B. Wood*

Main category: stat.ML

TL;DR: 本文提出算法优化高通量筛选以解决生物机器学习中的数据瓶颈，专注于仅收集阳性样本并通过生成模型校正缺失的负样本，显著加速学习。


<details>
  <summary>Details</summary>
Motivation: 生物机器学习常因数据规模不足受限，高通量筛选可并行测试大量蛋白质序列，有望缓解这一瓶颈。

Method: 引入算法优化高通量筛选，专注于大样本情况下仅收集阳性样本，并用生成模型校正缺失的负样本。

Result: 在抗体大规模筛选中验证方法有效，表明实验与推断协同设计可大幅加速学习。

Conclusion: 通过实验与推断的协同设计，能高效解决数据瓶颈并加速机器学习进程。

Abstract: Biological machine learning is often bottlenecked by a lack of scaled data.
One promising route to relieving data bottlenecks is through high throughput
screens, which can experimentally test the activity of $10^6-10^{12}$ protein
sequences in parallel. In this article, we introduce algorithms to optimize
high throughput screens for data creation and model training. We focus on the
large scale regime, where dataset sizes are limited by the cost of measurement
and sequencing. We show that when active sequences are rare, we maximize
information gain if we only collect positive examples of active sequences, i.e.
$x$ with $y>0$. We can correct for the missing negative examples using a
generative model of the library, producing a consistent and efficient estimate
of the true $p(y | x)$. We demonstrate this approach in simulation and on a
large scale screen of antibodies. Overall, co-design of experiments and
inference lets us accelerate learning dramatically.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Protein Folding with Neural Ordinary Differential Equations](https://arxiv.org/abs/2510.16253)
*Arielle Sanford,Shuo Sun,Christian B. Mendl*

Main category: cs.LG

TL;DR: 论文提出了一种基于神经ODE的连续深度Evoformer模型，替代原有离散模块，实现计算资源的高效利用，并在蛋白质结构预测任务中展示了一定的性能。


<details>
  <summary>Details</summary>
Motivation: 传统Evoformer模型的深度结构导致高计算成本和刚性分层离散化，限制了效率和灵活性。

Method: 利用神经ODE参数化替代48个离散块，保留核心注意力操作，通过伴随方法和自适应ODE求解器降低内存需求和运行时成本。

Result: 连续时间Evoformer在蛋白质结构预测中生成结构合理的结果，但精度略逊于原模型，资源消耗显著降低（单GPU训练17.5小时）。

Conclusion: 连续深度模型为生物分子建模提供了轻量化和可解释的替代方案，开辟了高效自适应蛋白质结构预测的新方向。

Abstract: Recent advances in protein structure prediction, such as AlphaFold, have
demonstrated the power of deep neural architectures like the Evoformer for
capturing complex spatial and evolutionary constraints on protein conformation.
However, the depth of the Evoformer, comprising 48 stacked blocks, introduces
high computational costs and rigid layerwise discretization. Inspired by Neural
Ordinary Differential Equations (Neural ODEs), we propose a continuous-depth
formulation of the Evoformer, replacing its 48 discrete blocks with a Neural
ODE parameterization that preserves its core attention-based operations. This
continuous-time Evoformer achieves constant memory cost (in depth) via the
adjoint method, while allowing a principled trade-off between runtime and
accuracy through adaptive ODE solvers. Benchmarking on protein structure
prediction tasks, we find that the Neural ODE-based Evoformer produces
structurally plausible predictions and reliably captures certain secondary
structure elements, such as alpha-helices, though it does not fully replicate
the accuracy of the original architecture. However, our model achieves this
performance using dramatically fewer resources, just 17.5 hours of training on
a single GPU, highlighting the promise of continuous-depth models as a
lightweight and interpretable alternative for biomolecular modeling. This work
opens new directions for efficient and adaptive protein structure prediction
frameworks.

</details>


### [4] [Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration](https://arxiv.org/abs/2510.16590)
*Alan Kai Hassen,Andrius Bernatavicius,Antonius P. A. Janssen,Mike Preuss,Gerard J. P. van Westen,Djork-Arné Clevert*

Main category: cs.LG

TL;DR: 本文提出了一种基于通用大型语言模型（LLM）的分子推理框架，无需标记数据即可工作，成功应用于单步逆合成任务，并显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 化学中机器学习应用常受限于标记数据的稀缺性和高昂成本，传统监督方法难以适用，因此开发一种不依赖标记数据的框架具有重要意义。

Method: 通过独特原子标识符将思维链推理锚定到分子结构，分为一步任务识别相关片段和化学标签，以及可选的多步骤任务预测化学转化。

Result: LLM在单步逆合成任务中表现出色，识别化学合理反应位点（≥90%）、命名反应类别（≥40%）和最终反应物（≥74%）的成功率高。

Conclusion: 该框架不仅解决了复杂化学任务，还提供了一种生成理论基础的合成数据的方法，缓解了数据稀缺问题。

Abstract: Applications of machine learning in chemistry are often limited by the
scarcity and expense of labeled data, restricting traditional supervised
methods. In this work, we introduce a framework for molecular reasoning using
general-purpose Large Language Models (LLMs) that operates without requiring
labeled training data. Our method anchors chain-of-thought reasoning to the
molecular structure by using unique atomic identifiers. First, the LLM performs
a one-shot task to identify relevant fragments and their associated chemical
labels or transformation classes. In an optional second step, this
position-aware information is used in a few-shot task with provided class
examples to predict the chemical transformation. We apply our framework to
single-step retrosynthesis, a task where LLMs have previously underperformed.
Across academic benchmarks and expert-validated drug discovery molecules, our
work enables LLMs to achieve high success rates in identifying chemically
plausible reaction sites ($\geq90\%$), named reaction classes ($\geq40\%$), and
final reactants ($\geq74\%$). Beyond solving complex chemical tasks, our work
also provides a method to generate theoretically grounded synthetic datasets by
mapping chemical knowledge onto the molecular structure and thereby addressing
data scarcity.

</details>


### [5] [A Standardized Benchmark for Machine-Learned Molecular Dynamics using Weighted Ensemble Sampling](https://arxiv.org/abs/2510.17187)
*Alexander Aghili,Andy Bruce,Daniel Sabo,Sanya Murdeshwar,Kevin Bachelor,Ionut Mistreanu,Ashwin Lokapally,Razvan Marinescu*

Main category: cs.LG

TL;DR: 提出了一种模块化基准测试框架，用于系统评估蛋白质分子动力学方法，支持多种模拟引擎和指标计算，并提供了多样化的蛋白质数据集。


<details>
  <summary>Details</summary>
Motivation: 当前分子动力学方法发展迅速，但缺乏标准化的验证工具和一致的评估指标，阻碍了方法的客观比较。

Method: 采用加权集合采样（WE）和TICA分析的进度坐标，构建灵活轻量级的模拟引擎接口，支持多种模拟方法。

Result: 提供了包含9种蛋白质的数据集和19种以上的评估指标，验证了框架在经典MD和机器学习模型中的实用性。

Conclusion: 开源平台为分子模拟社区提供了标准化和可重复的基准测试基础。

Abstract: The rapid evolution of molecular dynamics (MD) methods, including
machine-learned dynamics, has outpaced the development of standardized tools
for method validation. Objective comparison between simulation approaches is
often hindered by inconsistent evaluation metrics, insufficient sampling of
rare conformational states, and the absence of reproducible benchmarks. To
address these challenges, we introduce a modular benchmarking framework that
systematically evaluates protein MD methods using enhanced sampling analysis.
Our approach uses weighted ensemble (WE) sampling via The Weighted Ensemble
Simulation Toolkit with Parallelization and Analysis (WESTPA), based on
progress coordinates derived from Time-lagged Independent Component Analysis
(TICA), enabling fast and efficient exploration of protein conformational
space. The framework includes a flexible, lightweight propagator interface that
supports arbitrary simulation engines, allowing both classical force fields and
machine learning-based models. Additionally, the framework offers a
comprehensive evaluation suite capable of computing more than 19 different
metrics and visualizations across a variety of domains. We further contribute a
dataset of nine diverse proteins, ranging from 10 to 224 residues, that span a
variety of folding complexities and topologies. Each protein has been
extensively simulated at 300K for one million MD steps per starting point (4
ns). To demonstrate the utility of our framework, we perform validation tests
using classic MD simulations with implicit solvent and compare protein
conformational sampling using a fully trained versus under-trained CGSchNet
model. By standardizing evaluation protocols and enabling direct, reproducible
comparisons across MD approaches, our open-source platform lays the groundwork
for consistent, rigorous benchmarking across the molecular simulation
community.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [6] [Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity](https://arxiv.org/abs/2510.15975)
*Zaixi Zhang,Souradip Chakraborty,Amrit Singh Bedi,Emilin Mathew,Varsha Saravanan,Le Cong,Alvaro Velasquez,Sheng Lin-Gibson,Megan Blewett,Dan Hendrycs,Alex John London,Ellen Zhong,Ben Raphael,Jian Ma,Eric Xing,Russ Altman,George Church,Mengdi Wang*

Main category: cs.CR

TL;DR: 本文探讨了生成式人工智能（GenAI）在生物科学中的快速发展及其带来的双重用途风险，现有监管漏洞以及专家对AI滥用的担忧，并提出了多层次的安全防御策略。


<details>
  <summary>Details</summary>
Motivation: GenAI在生物科学领域的广泛应用带来了潜在的双重用途风险和安全漏洞，亟需有效的监管和技术措施以确保其安全使用。

Method: 通过130位专家的访谈和对现有威胁的分析，本文评估了GenAI在生物科学中的风险，并提出了多层次的安全防御策略，包括数据过滤、伦理对齐和实时监控。

Result: 研究发现76%的专家担心AI在生物学中的滥用，74%呼吁建立新的治理框架。提出了嵌入式安全技术的多层次防御策略。

Conclusion: 为保障GenAI在生物科学中的安全使用，需要采取即时的适应性治理和安全设计技术相结合的策略。

Abstract: The rapid adoption of generative artificial intelligence (GenAI) in the
biosciences is transforming biotechnology, medicine, and synthetic biology. Yet
this advancement is intrinsically linked to new vulnerabilities, as GenAI
lowers the barrier to misuse and introduces novel biosecurity threats, such as
generating synthetic viral proteins or toxins. These dual-use risks are often
overlooked, as existing safety guardrails remain fragile and can be
circumvented through deceptive prompts or jailbreak techniques. In this
Perspective, we first outline the current state of GenAI in the biosciences and
emerging threat vectors ranging from jailbreak attacks and privacy risks to the
dual-use challenges posed by autonomous AI agents. We then examine urgent gaps
in regulation and oversight, drawing on insights from 130 expert interviews
across academia, government, industry, and policy. A large majority ($\approx
76$\%) expressed concern over AI misuse in biology, and 74\% called for the
development of new governance frameworks. Finally, we explore technical
pathways to mitigation, advocating a multi-layered approach to GenAI safety.
These defenses include rigorous data filtering, alignment with ethical
principles during development, and real-time monitoring to block harmful
requests. Together, these strategies provide a blueprint for embedding security
throughout the GenAI lifecycle. As GenAI becomes integrated into the
biosciences, safeguarding this frontier requires an immediate commitment to
both adaptive governance and secure-by-design technologies.

</details>
