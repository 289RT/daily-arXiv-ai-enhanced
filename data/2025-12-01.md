<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [BeeRNA: tertiary structure-based RNA inverse folding using Artificial Bee Colony](https://arxiv.org/abs/2511.21781)
*Mehyar Mlaweh,Tristan Cazenave,Ines Alaya*

Main category: q-bio.BM

TL;DR: BeeRNA是一种基于人工蜂群算法的RNA逆折叠方法，专注于短至中等长度的RNA设计，具有高结构保真度和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决RNA三级结构的逆折叠问题，填补现有方法多专注于二级结构的不足。

Method: 结合人工蜂群算法、碱基对距离过滤和RMSD结构评估，采用两阶段适应度评估策略，并考虑热力学约束和自适应突变率。

Result: BeeRNA在短至中等长度RNA设计中表现出高结构保真度，且有实用CPU运行时间。

Conclusion: BeeRNA为RNA设计提供了一种轻量级、无需训练的生物启发方法，适用于治疗和生物技术领域。

Abstract: The Ribonucleic Acid (RNA) inverse folding problem, designing nucleotide sequences that fold into specific tertiary structures, is a fundamental computational biology problem with important applications in synthetic biology and bioengineering. The design of complex three-dimensional RNA architectures remains computationally demanding and mostly unresolved, as most existing approaches focus on secondary structures. In order to address tertiary RNA inverse folding, we present BeeRNA, a bio-inspired method that employs the Artificial Bee Colony (ABC) optimization algorithm. Our approach combines base-pair distance filtering with RMSD-based structural assessment using RhoFold for structure prediction, resulting in a two-stage fitness evaluation strategy. To guarantee biologically plausible sequences with balanced GC content, the algorithm takes thermodynamic constraints and adaptive mutation rates into consideration. In this work, we focus primarily on short and medium-length RNAs ($<$ 100 nucleotides), a biologically significant regime that includes microRNAs (miRNAs), aptamers, and ribozymes, where BeeRNA achieves high structural fidelity with practical CPU runtimes. The lightweight, training-free implementation will be publicly released for reproducibility, offering a promising bio-inspired approach for RNA design in therapeutics and biotechnology.

</details>


### [2] [DeepPNI: Language- and graph-based model for mutation-driven protein-nucleic acid energetics](https://arxiv.org/abs/2511.22239)
*Somnath Mondal,Tinkal Mondal,Soumajit Pramanik,Rukmankesh Mehra*

Main category: q-bio.BM

TL;DR: DeepPNI是一种基于深度学习的回归模型，用于预测蛋白质-核酸复合物中突变导致的结合自由能变化，整合结构特征和序列特征，表现优异且稳健。


<details>
  <summary>Details</summary>
Motivation: 蛋白质与核酸的相互作用对细胞功能至关重要，突变常导致疾病，而实验技术存在局限性，因此需要更有效的预测方法。

Method: 构建包含1951个突变的大型数据集，结合结构特征（通过RGCN编码）和序列特征（通过ESM-2提取），建立深度学习模型DeepPNI。

Result: 模型在大数据集中平均PCC达0.76，在蛋白质-DNA、蛋白质-RNA数据集及不同温度数据集上表现一致，且外部验证优于现有工具。

Conclusion: DeepPNI是一个通用的稳健模型，能有效预测突变对蛋白质-核酸复合物结合自由能的影响。

Abstract: The interaction between proteins and nucleic acids is crucial for processes that sustain cellular function, including DNA maintenance and the regulation of gene expression and translation. Amino acid mutations in protein-nucleic acid complexes often lead to vital diseases. Experimental techniques have their own specific limitations in predicting mutational effects in protein-nucleic acid complexes. In this study, we compiled a large dataset of 1951 mutations including both protein-DNA and protein-RNA complexes and integrated structural and sequential features to build a deep learning-based regression model named DeepPNI. This model estimates mutation-induced binding free energy changes in protein-nucleic acid complexes. The structural features are encoded via edge-aware RGCN and the sequential features are extracted using protein language model ESM-2. We have achieved a high average Pearson correlation coefficient (PCC) of 0.76 in the large dataset via five-fold cross-validation. Consistent performance across individual dataset of protein-DNA, protein-RNA complexes, and different experimental temperature split dataset make the model generalizable. Our model showed good performance in complex-based five-fold cross-validation, which proved its robustness. In addition, DeepPNI outperformed in external dataset validation, and comparison with existing tools

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Beyond Atoms: Evaluating Electron Density Representation for 3D Molecular Learning](https://arxiv.org/abs/2511.21900)
*Patricia Suriana,Joshua A. Rackers,Ewa M. Nowara,Pedro O. Pinheiro,John M. Nicoloudis,Vishnu Sresht*

Main category: cs.LG

TL;DR: 论文比较了三种基于体素的输入类型（原子类型、原始电子密度和密度梯度幅度）在3D卷积神经网络中的应用，结果显示密度输入在低数据量和量子属性预测中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有3D分子属性预测的机器学习模型依赖基于原子的表示方法，可能忽略细微的物理信息，而电子密度图谱提供了物理基础更强的连续替代方案。

Method: 研究使用三种体素输入类型（原子类型、原始电子密度和密度梯度幅度），在两个分子任务（蛋白质-配体结合亲和力预测和量子属性预测）中评估3D卷积神经网络的性能。

Result: 在PDBbind任务中，低数据条件下密度输入优于原子类型；在QM9任务中，密度输入在大规模数据下表现更优，反映了密度中编码的丰富结构信息。

Conclusion: 密度衍生的输入在不同任务和数据条件下的优势显著，提高了亲和力预测的数据效率和量子属性模型的准确性。

Abstract: Machine learning models for 3D molecular property prediction typically rely on atom-based representations, which may overlook subtle physical information. Electron density maps -- the direct output of X-ray crystallography and cryo-electron microscopy -- offer a continuous, physically grounded alternative. We compare three voxel-based input types for 3D convolutional neural networks (CNNs): atom types, raw electron density, and density gradient magnitude, across two molecular tasks -- protein-ligand binding affinity prediction (PDBbind) and quantum property prediction (QM9). We focus on voxel-based CNNs because electron density is inherently volumetric, and voxel grids provide the most natural representation for both experimental and computed densities. On PDBbind, all representations perform similarly with full data, but in low-data regimes, density-based inputs outperform atom types, while a shape-based baseline performs comparably -- suggesting that spatial occupancy dominates this task. On QM9, where labels are derived from Density Functional Theory (DFT) but input densities from a lower-level method (XTB), density-based inputs still outperform atom-based ones at scale, reflecting the rich structural and electronic information encoded in density. Overall, these results highlight the task- and regime-dependent strengths of density-derived inputs, improving data efficiency in affinity prediction and accuracy in quantum property modeling.

</details>
