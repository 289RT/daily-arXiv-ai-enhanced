<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [ABConformer: Physics-inspired Sliding Attention for Antibody-Antigen Interface Prediction](https://arxiv.org/abs/2509.23254)
*Zhang-Yu You,Jiahao Ma,Hongzong Li,Ye-Fan Hu,Jian-Dong Huang*

Main category: cs.LG

TL;DR: ABCONFORMER是一种基于Conformer主干的模型，无需依赖三维结构数据即可准确预测抗体-抗原界面。它在最新的SARS-CoV-2数据集上表现优异，并超越了广泛使用的基于序列的方法。


<details>
  <summary>Details</summary>
Motivation: 准确预测抗体-抗原界面对于疫苗设计、免疫诊断和治疗抗体开发至关重要，但仅从序列进行可靠预测仍然具有挑战性。

Method: ABCONFORMER引入了物理启发的滑动注意力机制，能够在不依赖三维结构数据的情况下捕获抗体-抗原相互作用的局部和全局特征。

Result: ABCONFORMER在SARS-CoV-2数据集上实现最佳性能，并在抗体无关的表位预测中超越现有方法。消融研究表明，滑动注意力显著提高了预测精度。

Conclusion: ABCONFORMER为序列级别的抗体-抗原界面预测提供了高效工具，可促进相关研究和应用。

Abstract: Accurate prediction of antibody-antigen (Ab-Ag) interfaces is critical for
vaccine design, immunodiagnostics, and therapeutic antibody development.
However, achieving reliable predictions from sequences alone remains a
challenge. In this paper, we present ABCONFORMER, a model based on the
Conformer backbone that captures both local and global features of a
biosequence. To accurately capture Ab-Ag interactions, we introduced the
physics-inspired sliding attention, enabling residue-level contact recovery
without relying on three-dimensional structural data. ABConformer can
accurately predict paratopes and epitopes given the antibody and antigen
sequence, and predict pan-epitopes on the antigen without antibody information.
In comparison experiments, ABCONFORMER achieves state-of-the-art performance on
a recent SARS-CoV-2 Ab-Ag dataset, and surpasses widely used sequence-based
methods for antibody-agnostic epitope prediction. Ablation studies further
quantify the contribution of each component, demonstrating that, compared to
conventional cross-attention, sliding attention significantly enhances the
precision of epitope prediction. To facilitate reproducibility, we will release
the code under an open-source license upon acceptance.

</details>


### [2] [MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models](https://arxiv.org/abs/2509.24779)
*Kacper Kapuśniak,Cristian Gabellini,Michael Bronstein,Prudencio Tossou,Francesco Di Giovanni*

Main category: cs.LG

TL;DR: 该论文提出了一种新的生成模型MSM Emulators，通过学习马尔可夫状态模型（MSM）定义的离散状态的跃迁，显著提高蛋白质动力学模拟的效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统分子动力学（MD）模拟计算成本高的问题，并提出通过生成模型替代昂贵的MD模拟。

Method: 引入了MarS-FM方法，通过学习MSM的离散状态跃迁，生成高效的替代轨迹。

Result: MarS-FM在多类蛋白质结构指标上优于现有方法，提供了超过两个数量级的加速。

Conclusion: MSM Emulators和MarS-FM在蛋白质动力学模拟中表现出优异的性能和泛化能力。

Abstract: Molecular Dynamics (MD) is a powerful computational microscope for probing
protein functions. However, the need for fine-grained integration and the long
timescales of biomolecular events make MD computationally expensive. To address
this, several generative models have been proposed to generate surrogate
trajectories at lower cost. Yet, these models typically learn a fixed-lag
transition density, causing the training signal to be dominated by frequent but
uninformative transitions. We introduce a new class of generative models, MSM
Emulators, which instead learn to sample transitions across discrete states
defined by an underlying Markov State Model (MSM). We instantiate this class
with Markov Space Flow Matching (MarS-FM), whose sampling offers more than two
orders of magnitude speedup compared to implicit- or explicit-solvent MD
simulations. We benchmark Mars-FM ability to reproduce MD statistics through
structural observables such as RMSD, radius of gyration, and secondary
structure content. Our evaluation spans protein domains (up to 500 residues)
with significant chemical and structural diversity, including unfolding events,
and enforces strict sequence dissimilarity between training and test sets to
assess generalization. Across all metrics, MarS-FM outperforms existing
methods, often by a substantial margin.

</details>


### [3] [TR2-D2: Tree Search Guided Trajectory-Aware Fine-Tuning for Discrete Diffusion](https://arxiv.org/abs/2509.25171)
*Sophia Tang,Yuchen Zhu,Molei Tao,Pranam Chatterjee*

Main category: cs.LG

TL;DR: 论文提出了一种称为TR2-D2的新框架，通过结合树搜索和随机最优控制，优化离散扩散模型的轨迹，以实现奖励引导的精细调优。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的扩散模型优化方法容易因训练过程中的次优轨迹而产生不良结果，需要一种更可靠的方法来改进精细调优。

Method: TR2-D2框架使用蒙特卡洛树搜索（MCTS）构建回放缓冲区，用于轨迹感知的精细调优，并结合随机最优控制目标优化预训练的离散扩散模型。

Result: 在生物序列扩散模型的单目标和多目标精细调优任务中，TR2-D2展现出了可靠性和有效性。

Conclusion: TR2-D2为离散序列生成中的奖励引导精细调优提供了一种创新且有效的方法。

Abstract: Reinforcement learning with stochastic optimal control offers a promising
framework for diffusion fine-tuning, where a pre-trained diffusion model is
optimized to generate paths that lead to a reward-tilted distribution. While
these approaches enable optimization without access to explicit samples from
the optimal distribution, they require training on rollouts under the current
fine-tuned model, making them susceptible to reinforcing sub-optimal
trajectories that yield poor rewards. To overcome this challenge, we introduce
TRee Search Guided TRajectory-Aware Fine-Tuning for Discrete Diffusion
(TR2-D2), a novel framework that optimizes reward-guided discrete diffusion
trajectories with tree search to construct replay buffers for trajectory-aware
fine-tuning. These buffers are generated using Monte Carlo Tree Search (MCTS)
and subsequently used to fine-tune a pre-trained discrete diffusion model under
a stochastic optimal control objective. We validate our framework on single-
and multi-objective fine-tuning of biological sequence diffusion models,
highlighting the overall effectiveness of TR2-D2 for reliable reward-guided
fine-tuning in discrete sequence generation.

</details>
