<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [Targeting Melanoma-Specific Tyrosinase: Cyclic Peptide Disrupts Actin Dynamics for Precision Apoptosis Induction](https://arxiv.org/abs/2507.06534)
*Ruoyang Zhao,Xiaowei Wang,Jiajia Hu,Qingqing Sun,Xinmin Zhao,Jun Guo,Feng Zhang,Min Wu*

Main category: q-bio.BM

TL;DR: 研究设计了一种靶向黑色素瘤的环肽系统c-RGDKYQ，通过酪氨酸酶触发自组装，选择性破坏癌细胞功能，抑制肿瘤生长。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤对传统疗法耐药性强且易转移，现有策略常伴随系统性毒性和耐药性问题。

Method: 利用黑色素瘤细胞中酪氨酸酶过表达，设计环肽c-RGDKYQ，通过酶介导氧化自组装形成纳米结构，选择性破坏细胞骨架。

Result: c-RGDKYQ对黑色素瘤细胞具有高选择性，显著抑制小鼠模型肿瘤生长，且系统性毒性低。

Conclusion: 靶向酪氨酸酶的c-RGDKYQ是黑色素瘤治疗的潜在替代方案。

Abstract: Melanoma is an aggressive and highly metastatic cancer that exhibits stubborn
resistance to conventional therapies, highlighting the need for novel
treatments. Existing therapeutic strategies often suffer from systemic
toxicity, poor efficacy and fast-gained drug resistance. In this study, we
designed a cyclic peptide system (c-RGDKYQ) that takes the advantage of the
overexpression of tyrosinase in melanoma cells to trigger enzyme-mediated
oxidation and self-assembly. The assembled peptide nanostructures can
selectively disrupt the actin cytoskeleton, impairing cancer cellular
functions, e.g., motility, adhesion, and proliferation, ultimately leading to
apoptosis. This approach does not rely on external drug payloads or complex
delivery mechanisms. c-RGDKYQ exhibits high selectivity for melanoma cells,
strongly suppressing tumor growth in a murine model with minimal systemic
toxicity. Our findings illuminate that, through targeting tyrosinase, c-RGDKYQ
may be an enzyme-responsive alternative to conventional treatments for
melanoma.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [2] [DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning](https://arxiv.org/abs/2507.07060)
*Shreyas Vinaya Sathyanarayana,Rahil Shah,Sharanabasava D. Hiremath,Rishikesh Panda,Rahul Jana,Riya Singh,Rida Irfan,Ashwin Murali,Bharath Ramsundar*

Main category: q-bio.QM

TL;DR: DeepRetro是一个结合模板搜索和LLM的迭代反馈框架，用于解决逆合成中多步规划问题，并能生成新路径。


<details>
  <summary>Details</summary>
Motivation: 传统逆合成方法依赖预定义模板，难以发现新路径，LLM在逆合成中的应用潜力尚未充分挖掘。

Method: DeepRetro整合模板引擎和LLM，通过迭代反馈循环提出并验证单步逆合成断键，动态探索路径。

Result: 基准测试和案例研究表明，DeepRetro能生成可行的新型逆合成路径，并通过人机交互优化结果。

Conclusion: 迭代LLM推理结合人类反馈，有望推动复杂化学合成的技术进步。

Abstract: Retrosynthesis, the identification of precursor molecules for a target
compound, is pivotal for synthesizing complex molecules, but faces challenges
in discovering novel pathways beyond predefined templates. Recent large
language model (LLM) approaches to retrosynthesis have shown promise but
effectively harnessing LLM reasoning capabilities for effective multi-step
planning remains an open question. To address this challenge, we introduce
DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic
framework. Our approach integrates the strengths of conventional
template-based/Monte Carlo tree search tools with the generative power of LLMs
in a step-wise, feedback-driven loop. Initially, synthesis planning is
attempted with a template-based engine. If this fails, the LLM subsequently
proposes single-step retrosynthetic disconnections. Crucially, these
suggestions undergo rigorous validity, stability, and hallucination checks
before the resulting precursors are recursively fed back into the pipeline for
further evaluation. This iterative refinement allows for dynamic pathway
exploration and correction. We demonstrate the potential of this pipeline
through benchmark evaluations and case studies, showcasing its ability to
identify viable and potentially novel retrosynthetic routes. In particular, we
develop an interactive graphical user interface that allows expert human
chemists to provide human-in-the-loop feedback to the reasoning algorithm. This
approach successfully generates novel pathways for complex natural product
compounds, demonstrating the potential for iterative LLM reasoning to advance
state-of-art in complex chemical syntheses.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction](https://arxiv.org/abs/2507.06366)
*Yupu Zhang,Zelin Xu,Tingsong Xiao,Gustavo Seabra,Yanjun Li,Chenglong Li,Zhe Jiang*

Main category: cs.LG

TL;DR: 论文提出DecoyDB数据集和自定义GCL框架，用于预训练图神经网络，显著提升蛋白质-配体结合亲和力预测的准确性、标签效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有PDBbind数据集规模小且缺乏高质量标记，限制了蛋白质-配体结合亲和力预测的进展，需通过自监督学习突破这一瓶颈。

Method: 构建DecoyDB数据集（包含高分辨率真实复合物和多样化的负样本），并设计定制的GCL框架进行预训练和微调。

Result: 实验证明基于DecoyDB预训练的模型在准确性、标签效率和泛化性上优于其他方法。

Conclusion: DecoyDB和GCL框架为蛋白质-配体结合亲和力预测提供了有效解决方案，推动了药物发现领域的发展。

Abstract: Predicting the binding affinity of protein-ligand complexes plays a vital
role in drug discovery. Unfortunately, progress has been hindered by the lack
of large-scale and high-quality binding affinity labels. The widely used
PDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,
especially graph contrastive learning (GCL), provides a unique opportunity to
break the barrier by pre-training graph neural network models based on vast
unlabeled complexes and fine-tuning the models on much fewer labeled complexes.
However, the problem faces unique challenges, including a lack of a
comprehensive unlabeled dataset with well-defined positive/negative complex
pairs and the need to design GCL algorithms that incorporate the unique
characteristics of such data. To fill the gap, we propose DecoyDB, a
large-scale, structure-aware dataset specifically designed for self-supervised
GCL on protein-ligand complexes. DecoyDB consists of high-resolution ground
truth complexes (less than 2.5 Angstrom) and diverse decoy structures with
computationally generated binding poses that range from realistic to suboptimal
(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation
(RMSD) from the native pose. We further design a customized GCL framework to
pre-train graph neural networks based on DecoyDB and fine-tune the models with
labels from PDBbind. Extensive experiments confirm that models pre-trained with
DecoyDB achieve superior accuracy, label efficiency, and generalizability.

</details>


### [4] [Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models](https://arxiv.org/abs/2507.06458)
*Arjun Banerjee,David Martinez,Camille Dang,Ethan Tam*

Main category: cs.LG

TL;DR: 本文提出了一种自动标注蛋白质语言模型（PLM）神经元的方法，揭示了神经元对多种生化特性的选择性敏感，并开发了基于神经元激活的蛋白质生成方法。


<details>
  <summary>Details</summary>
Motivation: 理解PLM内部神经元的生物信息编码机制，并利用这一信息生成具有特定特性的蛋白质。

Method: 引入自动化框架标注PLM神经元，开发神经元激活导向的蛋白质生成方法，分析不同模型规模中的神经元分布。

Result: 揭示了PLM神经元的多样性敏感特性，成功生成了具有目标生化特性和结构特征的蛋白质，发现了PLM的缩放规律和神经元空间分布结构。

Conclusion: 通过自动化标注和神经元激活导向的方法，实现了对PLM神经元生物信息的深入理解和有效利用，为蛋白质工程提供了新工具。

Abstract: Protein language models (PLMs) encode rich biological information, yet their
internal neuron representations are poorly understood. We introduce the first
automated framework for labeling every neuron in a PLM with biologically
grounded natural language descriptions. Unlike prior approaches relying on
sparse autoencoders or manual annotation, our method scales to hundreds of
thousands of neurons, revealing individual neurons are selectively sensitive to
diverse biochemical and structural properties. We then develop a novel neuron
activation-guided steering method to generate proteins with desired traits,
enabling convergence to target biochemical properties like molecular weight and
instability index as well as secondary and tertiary structural motifs,
including alpha helices and canonical Zinc Fingers. We finally show that
analysis of labeled neurons in different model sizes reveals PLM scaling laws
and a structured neuron space distribution.

</details>
