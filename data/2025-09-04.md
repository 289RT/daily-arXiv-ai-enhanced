<div id=toc></div>

# Table of Contents

- [q-bio.BM](#q-bio.BM) [Total: 1]


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [1] [SurGBSA: Learning Representations From Molecular Dynamics Simulations](https://arxiv.org/abs/2509.03084)
*Derek Jones,Yue Yang,Felice C. Lightstone,Niema Moshiri,Jonathan E. Allen,Tajana S. Rosing*

Main category: q-bio.BM

TL;DR: 论文提出了一种名为SurGBSA的新方法，利用分子动力学（MD）模拟数据进行预训练，显著提升了分子表示学习的性能，并在速度上取得了巨大优势。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多基于静态结构，限制了模型的泛化能力。研究旨在利用MD模拟数据开发更通用的模型，以提高对新分子结构的预测准确性。

Method: 提出了SurGBSA方法，通过预训练学习MMGBSA的替代函数，利用CASF-2016基准测试中的140万条MD轨迹数据进行训练。

Result: SurGBSA在速度上比传统物理方法快6,497倍，同时在姿势排名问题上几乎达到相同的准确性（仅相差-0.4%）。

Conclusion: 研究证明了基于MD模拟训练的模型改进潜力，推动了分子基础模型的发展，并将模型、代码和训练数据公开。

Abstract: Self-supervised pretraining from static structures of drug-like compounds and
proteins enable powerful learned feature representations. Learned features
demonstrate state of the art performance on a range of predictive tasks
including molecular properties, structure generation, and protein-ligand
interactions. The majority of approaches are limited by their use of static
structures and it remains an open question, how best to use atomistic molecular
dynamics (MD) simulations to develop more generalized models to improve
prediction accuracy for novel molecular structures. We present SURrogate mmGBSA
(SurGBSA) as a new modeling approach for MD-based representation learning,
which learns a surrogate function of the Molecular Mechanics Generalized Born
Surface Area (MMGBSA). We show for the first time the benefits of
physics-informed pre-training to train a surrogate MMGBSA model on a collection
of over 1.4 million 3D trajectories collected from MD simulations of the
CASF-2016 benchmark. SurGBSA demonstrates a dramatic 6,497x speedup versus a
traditional physics-based single-point MMGBSA calculation while nearly matching
single-point MMGBSA accuracy on the challenging pose ranking problem for
identification of the correct top pose (-0.4% difference). Our work advances
the development of molecular foundation models by showing model improvements
when training on MD simulations. Models, code and training data are made
publicly available.

</details>
