{"id": "2509.10871", "pdf": "https://arxiv.org/pdf/2509.10871", "abs": "https://arxiv.org/abs/2509.10871", "authors": ["Alma C. Castaneda-Leautaud", "Rommie E. Amaro"], "title": "Optimal message passing for molecular prediction is simple, attentive and spatial", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "32 pages, 12 figures. Preprint submitted to RSC Drug Discovery", "summary": "Strategies to improve the predicting performance of Message-Passing\nNeural-Networks for molecular property predictions can be achieved by\nsimplifying how the message is passed and by using descriptors that capture\nmultiple aspects of molecular graphs. In this work, we designed model\narchitectures that achieved state-of-the-art performance, surpassing more\ncomplex models such as those pre-trained on external databases. We assessed\ndataset diversity to complement our performance results, finding that\nstructural diversity influences the need for additional components in our MPNNs\nand feature sets.\n  In most datasets, our best architecture employs bidirectional message-passing\nwith an attention mechanism, applied to a minimalist message formulation that\nexcludes self-perception, highlighting that relatively simpler models, compared\nto classical MPNNs, yield higher class separability. In contrast, we found that\nconvolution normalization factors do not benefit the predictive power in all\nthe datasets tested. This was corroborated in both global and node-level\noutputs. Additionally, we analyzed the influence of both adding spatial\nfeatures and working with 3D graphs, finding that 2D molecular graphs are\nsufficient when complemented with appropriately chosen 3D descriptors. This\napproach not only preserves predictive performance but also reduces\ncomputational cost by over 50%, making it particularly advantageous for\nhigh-throughput screening campaigns.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7b80\u5316\u6d88\u606f\u4f20\u9012\u673a\u5236\u548c\u9009\u62e9\u591a\u7ef4\u5ea6\u5206\u5b50\u56fe\u63cf\u8ff0\u7b26\u6765\u63d0\u5347\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08MPNN\uff09\u9884\u6d4b\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u5176\u8bbe\u8ba1\u7684\u6a21\u578b\u67b6\u6784\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u590d\u6742\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u53d1\u73b02D\u5206\u5b50\u56fe\u7ed3\u5408\u9002\u5f533D\u63cf\u8ff0\u7b26\u53ef\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u6d88\u606f\u4f20\u9012\u673a\u5236\u548c\u63cf\u8ff0\u7b26\u9009\u62e9\uff0c\u63d0\u5347MPNN\u5728\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63a2\u7d22\u6a21\u578b\u7b80\u5316\u5bf9\u9884\u6d4b\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u4e86\u53cc\u5411\u6d88\u606f\u4f20\u9012\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\u67b6\u6784\uff0c\u6d4b\u8bd5\u4e86\u7b80\u5316\u6d88\u606f\u4f20\u9012\uff08\u53bb\u9664\u81ea\u611f\u77e5\uff09\u548c\u5377\u79ef\u5f52\u4e00\u5316\u56e0\u5b50\u7684\u6548\u679c\uff0c\u5e76\u8bc4\u4f30\u4e862D\u5206\u5b50\u56fe\u7ed3\u54083D\u63cf\u8ff0\u7b26\u7684\u5b9e\u7528\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5316\u6a21\u578b\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u590d\u6742\u7684MPNN\uff1b2D\u5206\u5b50\u56fe\u7ed3\u54083D\u63cf\u8ff0\u7b26\u53ef\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e50%\u4ee5\u4e0a\uff0c\u4e14\u4e0d\u5f71\u54cd\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u7b80\u5316\u6d88\u606f\u4f20\u9012\u673a\u5236\u548c\u5408\u7406\u7684\u63cf\u8ff0\u7b26\u9009\u62e9\u80fd\u663e\u8457\u63d0\u5347MPNN\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u9ad8\u901a\u91cf\u7b5b\u9009\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11044", "pdf": "https://arxiv.org/pdf/2509.11044", "abs": "https://arxiv.org/abs/2509.11044", "authors": ["Xuefeng Liu", "Songhao Jiang", "Qinan Huang", "Tinson Xu", "Ian Foster", "Mengdi Wang", "Hening Lin", "Jinbo Xu", "Rick Stevens"], "title": "FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Fragment-Based Drug Discovery (FBDD) is a popular approach in early drug\ndevelopment, but designing effective linkers to combine disconnected molecular\nfragments into chemically and pharmacologically viable candidates remains\nchallenging. Further complexity arises when fragments contain structural\nredundancies, like duplicate rings, which cannot be addressed by simply adding\nor removing atoms or bonds. To address these challenges in a unified framework,\nwe introduce FragmentGPT, which integrates two core components: (1) a novel\nchemically-aware, energy-based bond cleavage pre-training strategy that equips\nthe GPT-based model with fragment growing, linking, and merging capabilities,\nand (2) a novel Reward Ranked Alignment with Expert Exploration (RAE) algorithm\nthat combines expert imitation learning for diversity enhancement, data\nselection and augmentation for Pareto and composite score optimality, and\nSupervised Fine-Tuning (SFT) to align the learner policy with multi-objective\ngoals. Conditioned on fragment pairs, FragmentGPT generates linkers that\nconnect diverse molecular subunits while simultaneously optimizing for multiple\npharmaceutical goals. It also learns to resolve structural redundancies-such as\nduplicated fragments-through intelligent merging, enabling the synthesis of\noptimized molecules. FragmentGPT facilitates controlled, goal-driven molecular\nassembly. Experiments and ablation studies on real-world cancer datasets\ndemonstrate its ability to generate chemically valid, high-quality molecules\ntailored for downstream drug discovery tasks.", "AI": {"tldr": "FragmentGPT\u662f\u4e00\u79cd\u96c6\u6210\u5316\u5b66\u611f\u77e5\u548c\u80fd\u91cf\u57fa\u9884\u8bad\u7ec3\u7684\u65b0\u578b\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3FBDD\u4e2d\u8fde\u63a5\u7247\u6bb5\u548c\u7ed3\u6784\u5197\u4f59\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3FBDD\u4e2d\u8bbe\u8ba1\u6709\u6548\u8fde\u63a5\u7247\u6bb5\u548c\u7ed3\u6784\u5197\u4f59\u7684\u96be\u9898\u3002", "method": "\u7ed3\u5408\u5316\u5b66\u611f\u77e5\u9884\u8bad\u7ec3\u548cRAE\u7b97\u6cd5\uff0c\u751f\u6210\u591a\u76ee\u6807\u4f18\u5316\u7684\u5206\u5b50\u8fde\u63a5\u3002", "result": "\u751f\u6210\u7684\u5206\u5b50\u5728\u764c\u75c7\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u9002\u7528\u4e8e\u836f\u7269\u53d1\u73b0\u3002", "conclusion": "FragmentGPT\u4e3a\u5206\u5b50\u7ec4\u88c5\u63d0\u4f9b\u4e86\u53ef\u63a7\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11046", "pdf": "https://arxiv.org/pdf/2509.11046", "abs": "https://arxiv.org/abs/2509.11046", "authors": ["Seon-Geun Jeong", "Kyeong-Hwan Moon", "Won-Joo Hwang"], "title": "Hybrid Quantum Neural Networks for Efficient Protein-Ligand Binding Affinity Prediction", "categories": ["cs.ET", "cs.LG", "q-bio.BM"], "comment": "43 pages, 9 figures, and 12 tables. Accepted by EPJ Quantum\n  Technology", "summary": "Protein-ligand binding affinity is critical in drug discovery, but\nexperimentally determining it is time-consuming and expensive. Artificial\nintelligence (AI) has been used to predict binding affinity, significantly\naccelerating this process. However, the high-performance requirements and vast\ndatasets involved in affinity prediction demand increasingly large AI models,\nrequiring substantial computational resources and training time. Quantum\nmachine learning has emerged as a promising solution to these challenges. In\nparticular, hybrid quantum-classical models can reduce the number of parameters\nwhile maintaining or improving performance compared to classical counterparts.\nDespite these advantages, challenges persist: why hybrid quantum models achieve\nthese benefits, whether quantum neural networks (QNNs) can replace classical\nneural networks, and whether such models are feasible on noisy\nintermediate-scale quantum (NISQ) devices. This study addresses these\nchallenges by proposing a hybrid quantum neural network (HQNN) that empirically\ndemonstrates the capability to approximate non-linear functions in the latent\nfeature space derived from classical embedding. The primary goal of this study\nis to achieve a parameter-efficient model in binding affinity prediction while\nensuring feasibility on NISQ devices. Numerical results indicate that HQNN\nachieves comparable or superior performance and parameter efficiency compared\nto classical neural networks, underscoring its potential as a viable\nreplacement. This study highlights the potential of hybrid QML in computational\ndrug discovery, offering insights into its applicability and advantages in\naddressing the computational challenges of protein-ligand binding affinity\nprediction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff08HQNN\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u9884\u6d4b\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfAI\u6a21\u578b\u5bf9\u8ba1\u7b97\u8d44\u6e90\u7684\u9ad8\u9700\u6c42\u95ee\u9898\uff0c\u5e76\u5728\u53c2\u6570\u6548\u7387\u548c\u6027\u80fd\u4e0a\u5c55\u793a\u4e86\u6f5c\u529b\u3002", "motivation": "\u5b9e\u9a8c\u6d4b\u5b9a\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\u65e2\u8017\u65f6\u53c8\u6602\u8d35\uff0c\u4f20\u7edfAI\u6a21\u578b\u867d\u80fd\u52a0\u901f\u9884\u6d4b\u4f46\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6709\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u7814\u7a76\u63d0\u51faHQNN\u6a21\u578b\uff0c\u7ed3\u5408\u91cf\u5b50\u4e0e\u7ecf\u5178\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u91cf\u5e76\u5728NISQ\u8bbe\u5907\u4e0a\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660eHQNN\u5728\u6027\u80fd\u548c\u53c2\u6570\u6548\u7387\u4e0a\u4f18\u4e8e\u6216\u4e0e\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\u3002", "conclusion": "HQNN\u5c55\u73b0\u4e86\u6df7\u5408\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u89e3\u51b3\u8ba1\u7b97\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.11782", "pdf": "https://arxiv.org/pdf/2509.11782", "abs": "https://arxiv.org/abs/2509.11782", "authors": ["Bozhen Hu", "Cheng Tan", "Siyuan Li", "Jiangbin Zheng", "Sizhe Qiu", "Jun Xia", "Stan Z. Li"], "title": "Multimodal Regression for Enzyme Turnover Rates Prediction", "categories": ["cs.LG", "q-bio.BM"], "comment": "9 pages, 5 figures. This paper was withdrawn from the IJCAI 2025\n  proceedings due to the lack of participation in the conference and\n  presentation", "summary": "The enzyme turnover rate is a fundamental parameter in enzyme kinetics,\nreflecting the catalytic efficiency of enzymes. However, enzyme turnover rates\nremain scarce across most organisms due to the high cost and complexity of\nexperimental measurements. To address this gap, we propose a multimodal\nframework for predicting the enzyme turnover rate by integrating enzyme\nsequences, substrate structures, and environmental factors. Our model combines\na pre-trained language model and a convolutional neural network to extract\nfeatures from protein sequences, while a graph neural network captures\ninformative representations from substrate molecules. An attention mechanism is\nincorporated to enhance interactions between enzyme and substrate\nrepresentations. Furthermore, we leverage symbolic regression via\nKolmogorov-Arnold Networks to explicitly learn mathematical formulas that\ngovern the enzyme turnover rate, enabling interpretable and accurate\npredictions. Extensive experiments demonstrate that our framework outperforms\nboth traditional and state-of-the-art deep learning approaches. This work\nprovides a robust tool for studying enzyme kinetics and holds promise for\napplications in enzyme engineering, biotechnology, and industrial biocatalysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u6a21\u6001\u6846\u67b6\uff0c\u6574\u5408\u9176\u5e8f\u5217\u3001\u5e95\u7269\u7ed3\u6784\u548c\u73af\u5883\u56e0\u7d20\uff0c\u9884\u6d4b\u9176\u5468\u8f6c\u7387\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u4ea4\u4e92\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u9176\u5468\u8f6c\u7387\u662f\u9176\u52a8\u529b\u5b66\u7684\u5173\u952e\u53c2\u6570\uff0c\u4f46\u7531\u4e8e\u5b9e\u9a8c\u6d4b\u91cf\u6210\u672c\u9ad8\u4e14\u590d\u6742\uff0c\u6570\u636e\u7a00\u7f3a\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u9176\u5e8f\u5217\u7279\u5f81\uff0c\u56fe\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u5e95\u7269\u5206\u5b50\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u4ea4\u4e92\uff0c\u5e76\u5229\u7528\u7b26\u53f7\u56de\u5f52\u5b66\u4e60\u6570\u5b66\u516c\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u9176\u5468\u8f6c\u7387\u9884\u6d4b\u4e0a\u4f18\u4e8e\u4f20\u7edf\u548c\u6700\u65b0\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9176\u52a8\u529b\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\uff0c\u5e76\u6709\u671b\u5e94\u7528\u4e8e\u9176\u5de5\u7a0b\u3001\u751f\u7269\u6280\u672f\u548c\u5de5\u4e1a\u751f\u7269\u50ac\u5316\u9886\u57df\u3002"}}
