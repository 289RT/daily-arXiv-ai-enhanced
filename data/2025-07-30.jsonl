{"id": "2507.21417", "pdf": "https://arxiv.org/pdf/2507.21417", "abs": "https://arxiv.org/abs/2507.21417", "authors": ["Xiang Liu", "Xuefei Huang", "Guo-Wei Wei"], "title": "Machine-Learning Prediction of Virus-like Particle Stoichiometry and Stability using Persistent Topological Laplacians", "categories": ["q-bio.BM"], "comment": null, "summary": "Understanding the stoichiometry and associated stability of virus-like\nparticles (VLPs) is crucial for optimizing their assembly efficiency and\nimmunogenic properties, which are essential for advancing biotechnology,\nvaccine design, and drug delivery. However, current experimental methods for\ndetermining VLP stoichiometry are labor-intensive, and time consuming. Machine\nlearning approaches have hardly been applied to the study of VLPs. To address\nthis challenge, we introduce a novel persistent Laplacian-based machine\nlearning (PLML) mode that leverages both harmonic and non-harmonic spectra to\ncapture intricate topological and geometric features of VLP structures. This\napproach achieves superior performance on the VLP200 dataset compared to\nexisting methods. To further assess robustness and generalizability, we\ncollected a new dataset, VLP706, containing 706 VLP samples with expanded\nstoichiometry diversity. Our PLML model maintains strong predictive accuracy on\nVLP706. Additionally, through random sequence perturbative mutation analysis,\nwe found that 60-mers and 180-mers exhibit greater stability than 240-mers and\n420-mers."}
{"id": "2507.21938", "pdf": "https://arxiv.org/pdf/2507.21938", "abs": "https://arxiv.org/abs/2507.21938", "authors": ["Alex Abrudan", "Sebastian Pujalte Ojeda", "Chaitanya K. Joshi", "Matthew Greenig", "Felipe Engelberger", "Alena Khmelinskaia", "Jens Meiler", "Michele Vendruscolo", "Tuomas P. J. Knowles"], "title": "Multi-state Protein Design with DynamicMPNN", "categories": ["cs.LG", "q-bio.BM", "I.2.6; J.3"], "comment": "ICML 2025 GenBio Workshop", "summary": "Structural biology has long been dominated by the one sequence, one\nstructure, one function paradigm, yet many critical biological processes - from\nenzyme catalysis to membrane transport - depend on proteins that adopt multiple\nconformational states. Existing multi-state design approaches rely on post-hoc\naggregation of single-state predictions, achieving poor experimental success\nrates compared to single-state design. We introduce DynamicMPNN, an inverse\nfolding model explicitly trained to generate sequences compatible with multiple\nconformations through joint learning across conformational ensembles. Trained\non 46,033 conformational pairs covering 75% of CATH superfamilies and evaluated\nusing AlphaFold initial guess, DynamicMPNN outperforms ProteinMPNN by up to 13%\non structure-normalized RMSD across our challenging multi-state protein\nbenchmark."}
